{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import heapq\n",
    "\n",
    "from numpy.typing import NDArray\n",
    "from typing import Callable\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler, Normalizer\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from ruzicka.test_metrics import minmax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorizing\n",
    "\n",
    "Here we use the same configuration as for the [GI Notebook](nux_imposters_ngram.ipynb), i.e. 5000 most-frequent 2-,3-, and 4-grams, with _z_-scaling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_ngrams_std = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        use_idf=False,\n",
    "        norm=\"l2\",\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(2, 4),\n",
    "        max_features=5000,\n",
    "    ),\n",
    "    StandardScaler(\n",
    "        with_mean=False\n",
    "    ),  # never centre frequency data for the minmax metric!\n",
    "    FunctionTransformer(lambda x: np.array(x.todense()), accept_sparse=True),\n",
    "    Normalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vecs = pd.read_csv(\"../repro/elegy_corpus.csv\", index_col=0)\n",
    "non_elegy_vecs = pd.read_csv(\"../repro/non_elegy_corpus.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = pd.concat([vecs, non_elegy_vecs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Work</th>\n",
       "      <th>Poem</th>\n",
       "      <th>LEN</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 1</td>\n",
       "      <td>116</td>\n",
       "      <td>hank tua penelope lento tibi mittit ulikse\\nni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 2</td>\n",
       "      <td>148</td>\n",
       "      <td>hospita demopoon tua te rodopeia pyllis\\nultra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 3</td>\n",
       "      <td>154</td>\n",
       "      <td>kwam legis a rapta briseide littera wenit\\nwik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 4</td>\n",
       "      <td>176</td>\n",
       "      <td>kwam nisi tu dederis karitura_st ipsa salutem\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 5</td>\n",
       "      <td>158</td>\n",
       "      <td>perlegis an konjunks prohibet nowa perlege non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>V.Flaccus</td>\n",
       "      <td>195-Argonautica</td>\n",
       "      <td>195-Argonautica</td>\n",
       "      <td>98</td>\n",
       "      <td>si pelopis duros prior hippodamia labores\\neks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>Lucretius</td>\n",
       "      <td>196-DRN</td>\n",
       "      <td>196-DRN</td>\n",
       "      <td>93</td>\n",
       "      <td>dekiderunt kwo_kwet in talis wenere meatus\\nkw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>Horace</td>\n",
       "      <td>197-Hor.</td>\n",
       "      <td>197-Hor. Sat.</td>\n",
       "      <td>94</td>\n",
       "      <td>eksirem plures kalones atkwe kaballi\\npaskendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>198-Aeneid</td>\n",
       "      <td>198-Aeneid</td>\n",
       "      <td>106</td>\n",
       "      <td>in lukem genito_ramyko dedit et fake praenjas\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>199-Georgics</td>\n",
       "      <td>199-Georgics</td>\n",
       "      <td>31</td>\n",
       "      <td>tum pater omnipotens fekundis imbribus aeter\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author             Work             Poem  LEN  \\\n",
       "0         Ovid              Ep.            Ep. 1  116   \n",
       "1         Ovid              Ep.            Ep. 2  148   \n",
       "2         Ovid              Ep.            Ep. 3  154   \n",
       "3         Ovid              Ep.            Ep. 4  176   \n",
       "4         Ovid              Ep.            Ep. 5  158   \n",
       "..         ...              ...              ...  ...   \n",
       "195  V.Flaccus  195-Argonautica  195-Argonautica   98   \n",
       "196  Lucretius          196-DRN          196-DRN   93   \n",
       "197     Horace         197-Hor.    197-Hor. Sat.   94   \n",
       "198     Vergil       198-Aeneid       198-Aeneid  106   \n",
       "199     Vergil     199-Georgics     199-Georgics   31   \n",
       "\n",
       "                                                 Chunk  \n",
       "0    hank tua penelope lento tibi mittit ulikse\\nni...  \n",
       "1    hospita demopoon tua te rodopeia pyllis\\nultra...  \n",
       "2    kwam legis a rapta briseide littera wenit\\nwik...  \n",
       "3    kwam nisi tu dederis karitura_st ipsa salutem\\...  \n",
       "4    perlegis an konjunks prohibet nowa perlege non...  \n",
       "..                                                 ...  \n",
       "195  si pelopis duros prior hippodamia labores\\neks...  \n",
       "196  dekiderunt kwo_kwet in talis wenere meatus\\nkw...  \n",
       "197  eksirem plures kalones atkwe kaballi\\npaskendi...  \n",
       "198  in lukem genito_ramyko dedit et fake praenjas\\...  \n",
       "199  tum pater omnipotens fekundis imbribus aeter\\n...  \n",
       "\n",
       "[470 rows x 5 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = corpus[corpus.Author != \"ps-Ovid\"]\n",
    "test_corpus = test_corpus[test_corpus.LEN >= 20]\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = LabelEncoder()\n",
    "labels = lenc.fit_transform(test_corpus.Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vec_ngrams_std.fit_transform(test_corpus.Chunk)\n",
    "y = np.array(lenc.fit_transform(test_corpus.Author))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "problems = corpus[corpus.Author == \"ps-Ovid\"]\n",
    "probs_X = vec_ngrams_std.transform(problems.Chunk)\n",
    "problem_dict = dict(zip(problems.Poem, probs_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BDI Implementation\n",
    "\n",
    "Vectorisation and Distance are both abstract."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_imposters(\n",
    "    test_vec: NDArray[float],\n",
    "    X: NDArray[NDArray[float]],\n",
    "    y: NDArray[int],\n",
    "    cand_idx: int,\n",
    "    n: int,\n",
    "    pct: float,\n",
    "    dist_fn: Callable[[NDArray[float], NDArray[float]], float],\n",
    "    method: str = \"random\",\n",
    "    rng: np.random.Generator = np.random.default_rng(),\n",
    ") -> list[float]:\n",
    "    # X at the row indices where y matches the condition\n",
    "    candidates = X[(y == cand_idx).nonzero()]\n",
    "    others = X[(y != cand_idx).nonzero()]\n",
    "    differences: list[float] = []\n",
    "    cand_samps: NDArray[float] = []\n",
    "    other_samps: NDArray[float] = []\n",
    "    if method == \"random\":\n",
    "        # choose n random row indices with replacement, all columns. This will\n",
    "        # still work if n > num_candidates because it will oversample.\n",
    "        cand_samps = candidates[rng.choice(candidates.shape[0], n, replace=True), :]\n",
    "        other_samps = others[rng.choice(others.shape[0], n, replace=True), :]\n",
    "\n",
    "    # At each bootstrap iteration we choose a different feature subset\n",
    "    for i in range(n):\n",
    "        # from 1d vectors, choose (pct * width_of_X) random column indices (no\n",
    "        # replacement)\n",
    "        ridx = rng.choice(X.shape[1], int(X.shape[1] * pct), replace=False)\n",
    "\n",
    "        # compare the test vector to one in-sample and one outsample (with\n",
    "        # bootstrap columns), then record the difference of distances\n",
    "        if method == \"random\":\n",
    "            in_dist = dist_fn(test_vec[ridx], cand_samps[i][ridx])\n",
    "            out_dist = dist_fn(test_vec[ridx], other_samps[i][ridx])\n",
    "            differences.append(out_dist - in_dist)\n",
    "\n",
    "        # compare the test vector to the closest in-sample and out-sample, then\n",
    "        # record the difference of distances (like vanilla Kestemont GI)\n",
    "        elif method == \"closest\":\n",
    "            in_dists = [\n",
    "                dist_fn(test_vec[ridx], cand_samp[ridx]) for cand_samp in candidates\n",
    "            ]\n",
    "            out_dists = [\n",
    "                dist_fn(test_vec[ridx], other_samp[ridx]) for other_samp in others\n",
    "            ]\n",
    "            differences.append(min(out_dists) - min(in_dists))\n",
    "\n",
    "        # compare the test vector to the closest in-sample and out-sample, then\n",
    "        # record the scaled difference of distances for the smallest 3 (like\n",
    "        # Kestemont GI with Eder Boostrap Consensus Tree stye ranking)\n",
    "        elif method == \"ranked\":\n",
    "            in_dists = [\n",
    "                dist_fn(test_vec[ridx], cand_samp[ridx]) for cand_samp in candidates\n",
    "            ]\n",
    "            out_dists = [\n",
    "                dist_fn(test_vec[ridx], other_samp[ridx]) for other_samp in others\n",
    "            ]\n",
    "            # faster than sorting and slicing\n",
    "            top_in = heapq.nsmallest(3, in_dists)\n",
    "            top_out = heapq.nsmallest(3, out_dists)\n",
    "            d = 0\n",
    "            for n in range(3):\n",
    "                # smallest distances are unscaled, seccond is halved, etc\n",
    "                d += (top_out[n] - top_in[n]) / (n + 1)\n",
    "            differences.append(d)\n",
    "        else:\n",
    "            raise ValueError(\n",
    "                f\"Unsupported method {method}, valid are: random, closest, ranked\"\n",
    "            )\n",
    "    return differences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "\n",
    "As with the [GI Notebook](nux_imposters_ngram.ipynb), all of the problem texts are shown as closer to Ovid than to any of the imposter authors, in lexico-grammatical style."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for poem, vec in problem_dict.items():\n",
    "    bs = bootstrap_imposters(\n",
    "        vec,\n",
    "        X,\n",
    "        y,\n",
    "        lenc.transform([\"Ovid\"])[0],\n",
    "        1000,\n",
    "        0.35,\n",
    "        minmax,\n",
    "        \"ranked\",\n",
    "        rng=np.random.default_rng(seed=42),\n",
    "    )\n",
    "    results[poem] = bs\n",
    "\n",
    "df = pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nux            > Uncertainty (%): 0.00\n",
      "Medicamina     > Uncertainty (%): 0.00\n",
      "Consolatio 1   > Uncertainty (%): 0.00\n",
      "Consolatio 2   > Uncertainty (%): 0.00\n",
      "Consolatio 3   > Uncertainty (%): 0.00\n",
      "Ibis 1         > Uncertainty (%): 0.00\n",
      "Ibis 2         > Uncertainty (%): 0.00\n",
      "Ibis 3         > Uncertainty (%): 0.00\n",
      "Ibis 4         > Uncertainty (%): 0.00\n"
     ]
    }
   ],
   "source": [
    "for poem, ary in results.items():\n",
    "    print(f\"{poem:<15}> Uncertainty (%): {sp.stats.percentileofscore(ary, 0):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Production Figure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext rpy2.ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>variable</th>\n",
       "      <th>value</th>\n",
       "      <th>cons</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nux</td>\n",
       "      <td>0</td>\n",
       "      <td>0.128997</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Medicamina</td>\n",
       "      <td>0</td>\n",
       "      <td>0.035185</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Consolatio 1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.086219</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Consolatio 2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.074263</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Consolatio 3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.064741</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          index variable     value   cons\n",
       "0           Nux        0  0.128997  False\n",
       "1    Medicamina        0  0.035185  False\n",
       "2  Consolatio 1        0  0.086219   True\n",
       "3  Consolatio 2        0  0.074263   True\n",
       "4  Consolatio 3        0  0.064741   True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# for ggplot for this kind of plot it is easier to have 'long' tables, so we\n",
    "# melt the dataframe so each observation for each text is a 'variable'. We add a\n",
    "# column just so we can highlight the _Consolatio_ in a different colour.\n",
    "\n",
    "dff = df.T\n",
    "dff.reset_index(inplace=True)\n",
    "tst = dff.melt(id_vars=[\"index\"])\n",
    "tst[\"cons\"] = tst[\"index\"].str.startswith(\"Cons\")\n",
    "tst.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Cell magic `%%R` not found.\n"
     ]
    }
   ],
   "source": [
    "%%R -i tst -h 4.5 -w 8 -u in -r 300\n",
    "library(ggridges)\n",
    "library(paletteer)\n",
    "library(ggplot2)\n",
    "library(showtext)\n",
    "font_add_google(\"Roboto Condensed\", \"fnt\", regular.wt=400)\n",
    "showtext_auto()\n",
    "\n",
    "plt <- \"ggsci::category10_d3\"\n",
    "bgcol <- 'white'\n",
    "fgcol <- 'black'\n",
    "\n",
    "ggplot(data=tst,aes(value,y=index,fill=cons,color=cons)) +\n",
    "coord_cartesian(clip = \"off\") +\n",
    "\n",
    "ggridges::stat_density_ridges(\n",
    "    quantile_lines = FALSE, quantiles = 2, \n",
    "    alpha = .4, size = 0.5,\n",
    ") +\n",
    "geom_vline(xintercept=0, colour=fgcol, linetype='dashed', size=0.3) +\n",
    "scale_y_discrete() +\n",
    "scale_color_paletteer_d(plt) +\n",
    "scale_fill_paletteer_d(plt) +\n",
    "theme_bw() +\n",
    "xlab(\"\") +\n",
    "ylab(\"\") +\n",
    "ggtitle(\"Bootstrap Match Strength (Lexico-Grammatical Style) vs Ovid\") +\n",
    "theme(\n",
    "    panel.border = element_blank(),\n",
    "    plot.margin=unit(c(0,0,0,0),\"mm\"),\n",
    "    legend.position='none',\n",
    "    panel.background = element_rect(fill = bgcol,color=bgcol),\n",
    "    plot.background = element_rect(fill = bgcol,color=bgcol),\n",
    "    plot.title = element_text(hjust = 0.5, size=16, family=\"fnt\", color=fgcol),\n",
    "    axis.line.x=element_line(size=0.2,color=fgcol),\n",
    "    axis.line.y=element_line(size=0.2,color=fgcol),\n",
    "    axis.ticks.x=element_line(size=0.2,color=fgcol),\n",
    "    axis.ticks.y=element_line(size=0.2,color=fgcol),\n",
    "    axis.text.x=element_text(size=9, family=\"fnt\", color=fgcol),\n",
    "    axis.text.y=element_text(size=12, family=\"fnt\", color=fgcol),\n",
    "    panel.grid.major = element_blank(),\n",
    "    panel.grid.minor = element_blank(),\n",
    ")\n",
    "\n",
    "# fn <- \"figures/bootstrap_lexical_paper.png\"\n",
    "# ggsave(fn, dpi=600, width=8, height=4.5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "208657b13d9d01f546253097cf6f870938d682edd7d0d269d6436fd16db9d0e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

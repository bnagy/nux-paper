{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cluster Analysis: Lexico-grammatical style (S. 5.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from mqdq import utils, babble, ngrams\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy as sp\n",
    "\n",
    "import glob\n",
    "\n",
    "from sklearn.preprocessing import Normalizer, LabelEncoder, StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from ruzicka.Order2Verifier import Order2Verifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=\"INFO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "elegy_vecs = pd.read_csv(\"elegy_corpus.csv\", index_col=0)\n",
    "elegy_corpus = elegy_vecs[elegy_vecs.LEN >= 20]\n",
    "hexameter_vecs = pd.read_csv(\"non_elegy_corpus.csv\", index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Work</th>\n",
       "      <th>Poem</th>\n",
       "      <th>LEN</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 1</td>\n",
       "      <td>116</td>\n",
       "      <td>hank tua penelope lento tibi mittit ulikse\\nni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 2</td>\n",
       "      <td>148</td>\n",
       "      <td>hospita demopoon tua te rodopeia pyllis\\nultra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 3</td>\n",
       "      <td>154</td>\n",
       "      <td>kwam legis a rapta briseide littera wenit\\nwik...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 4</td>\n",
       "      <td>176</td>\n",
       "      <td>kwam nisi tu dederis karitura_st ipsa salutem\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ovid</td>\n",
       "      <td>Ep.</td>\n",
       "      <td>Ep. 5</td>\n",
       "      <td>158</td>\n",
       "      <td>perlegis an konjunks prohibet nowa perlege non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>465</th>\n",
       "      <td>V.Flaccus</td>\n",
       "      <td>195-Argonautica</td>\n",
       "      <td>195-Argonautica</td>\n",
       "      <td>98</td>\n",
       "      <td>si pelopis duros prior hippodamia labores\\neks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>466</th>\n",
       "      <td>Lucretius</td>\n",
       "      <td>196-DRN</td>\n",
       "      <td>196-DRN</td>\n",
       "      <td>93</td>\n",
       "      <td>dekiderunt kwo_kwet in talis wenere meatus\\nkw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>467</th>\n",
       "      <td>Horace</td>\n",
       "      <td>197-Hor.</td>\n",
       "      <td>197-Hor. Sat.</td>\n",
       "      <td>94</td>\n",
       "      <td>eksirem plures kalones atkwe kaballi\\npaskendi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>198-Aeneid</td>\n",
       "      <td>198-Aeneid</td>\n",
       "      <td>106</td>\n",
       "      <td>in lukem genito_ramyko dedit et fake praenjas\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>469</th>\n",
       "      <td>Vergil</td>\n",
       "      <td>199-Georgics</td>\n",
       "      <td>199-Georgics</td>\n",
       "      <td>31</td>\n",
       "      <td>tum pater omnipotens fekundis imbribus aeter\\n...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>470 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Author             Work             Poem  LEN  \\\n",
       "0         Ovid              Ep.            Ep. 1  116   \n",
       "1         Ovid              Ep.            Ep. 2  148   \n",
       "2         Ovid              Ep.            Ep. 3  154   \n",
       "3         Ovid              Ep.            Ep. 4  176   \n",
       "4         Ovid              Ep.            Ep. 5  158   \n",
       "..         ...              ...              ...  ...   \n",
       "465  V.Flaccus  195-Argonautica  195-Argonautica   98   \n",
       "466  Lucretius          196-DRN          196-DRN   93   \n",
       "467     Horace         197-Hor.    197-Hor. Sat.   94   \n",
       "468     Vergil       198-Aeneid       198-Aeneid  106   \n",
       "469     Vergil     199-Georgics     199-Georgics   31   \n",
       "\n",
       "                                                 Chunk  \n",
       "0    hank tua penelope lento tibi mittit ulikse\\nni...  \n",
       "1    hospita demopoon tua te rodopeia pyllis\\nultra...  \n",
       "2    kwam legis a rapta briseide littera wenit\\nwik...  \n",
       "3    kwam nisi tu dederis karitura_st ipsa salutem\\...  \n",
       "4    perlegis an konjunks prohibet nowa perlege non...  \n",
       "..                                                 ...  \n",
       "465  si pelopis duros prior hippodamia labores\\neks...  \n",
       "466  dekiderunt kwo_kwet in talis wenere meatus\\nkw...  \n",
       "467  eksirem plures kalones atkwe kaballi\\npaskendi...  \n",
       "468  in lukem genito_ramyko dedit et fake praenjas\\...  \n",
       "469  tum pater omnipotens fekundis imbribus aeter\\n...  \n",
       "\n",
       "[470 rows x 5 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus = pd.concat(\n",
    "    [elegy_corpus[elegy_corpus.Author != \"ps-Ovid\"], hexameter_vecs]\n",
    ").reset_index(drop=True)\n",
    "test_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lenc = LabelEncoder()\n",
    "labels = lenc.fit_transform(test_corpus.Author)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ruzicka.score_shifting import ScoreShifter\n",
    "from ruzicka.evaluation import pan_metrics\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kestemont flavoured GI relies on 'fitting' the score shifting to optimise the\n",
    "# combination of C@1 accuracy and the AUC score. However, to calculate the AUC\n",
    "# we need an idea of true negatives (correctly identifying that the sample does\n",
    "# not match the alleged label). This method simple takes the X, y data and\n",
    "# appends a copy of X where the label is incorrect (uniformly random untrue\n",
    "# label)\n",
    "\n",
    "\n",
    "def make_up_lies(X, y):\n",
    "    lies_labels = []\n",
    "    n_labels = max(y) + 1\n",
    "    for lab in y:\n",
    "        while True:\n",
    "            r = np.random.randint(n_labels)\n",
    "            if r != lab:\n",
    "                lies_labels.append(r)\n",
    "                break\n",
    "    ret_X = np.concatenate([X, X.copy()])\n",
    "    ret_y = np.concatenate([y, lies_labels])\n",
    "    ground_truth = np.concatenate([[1.0] * len(X), [0.0] * len(X)])\n",
    "    return (ret_X, ret_y, ground_truth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(\"ruzicka\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set to logging.DEBUG or higher for less noise\n",
    "\n",
    "for handler in logger.handlers:\n",
    "    handler.setLevel(logging.INFO)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifier options\n",
    "\n",
    "verifier_nini = Order2Verifier(\n",
    "    metric=\"nini\", base=\"instance\", nb_bootstrap_iter=500, rnd_prop=0.35\n",
    ")\n",
    "\n",
    "verifier_minmax = Order2Verifier(\n",
    "    metric=\"minmax\", base=\"instance\", nb_bootstrap_iter=500, rnd_prop=0.35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitter\n",
    "\n",
    "sss = StratifiedShuffleSplit(n_splits=10, test_size=0.1, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorizer options\n",
    "\n",
    "vec_ngrams_std = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        use_idf=False,\n",
    "        norm=\"l2\",\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(2, 4),\n",
    "        max_features=5000,\n",
    "    ),\n",
    "    StandardScaler(with_mean=False),\n",
    "    FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    "    Normalizer(),\n",
    ")\n",
    "\n",
    "vec_5grams = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        use_idf=False,\n",
    "        norm=\"l2\",\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(5, 5),\n",
    "        max_features=5000,\n",
    "    ),\n",
    "    FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_shifter(\n",
    "    X,\n",
    "    y,\n",
    "    vectorizer,\n",
    "    verifier,\n",
    "    shifter,\n",
    "    test_size=0.2,\n",
    "):\n",
    "    logger.info(f\"Fitting the provided score shifter on a {test_size*100}% sample\")\n",
    "    splitter = StratifiedShuffleSplit(n_splits=1, test_size=test_size)\n",
    "    for i, (train_index, test_index) in enumerate(splitter.split(X, y)):\n",
    "        train_X = vectorizer.fit_transform(X[train_index], y[train_index])\n",
    "        verifier.fit(train_X, y[train_index])\n",
    "        test_X_raw = vectorizer.transform(X[test_index])\n",
    "        logger.info(\"Running verifier on sub-sample\")\n",
    "        test_X, test_y, test_gt = make_up_lies(test_X_raw, y[test_index])\n",
    "        test_scores = verifier.predict_proba(test_X, test_y, nb_imposters=30)\n",
    "        logger.info(f\"Actually fitting...\")\n",
    "        shifter.fit(predicted_scores=test_scores, ground_truth_scores=test_gt)\n",
    "    return shifter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_imposters(X, y, splitter, vectorizer, verifier, shifter):\n",
    "    accs = []\n",
    "    c_at_1s = []\n",
    "    for i, (train_index, test_index) in enumerate(splitter.split(X, y)):\n",
    "        train_X = vectorizer.fit_transform(X[train_index], y[train_index])\n",
    "        verifier.fit(train_X, y[train_index])\n",
    "        test_X_raw = vectorizer.transform(X[test_index])\n",
    "        test_X, test_y, test_gt = make_up_lies(test_X_raw, y[test_index])\n",
    "        test_scores = verifier.predict_proba(test_X, test_y, nb_imposters=30)\n",
    "        logger.info(f\"Transforming {len(test_scores)} test scores...\")\n",
    "        test_scores = shifter.transform(test_scores)\n",
    "        dev_acc_score, dev_auc_score, dev_c_at_1_score = pan_metrics(\n",
    "            prediction_scores=test_scores, ground_truth_scores=test_gt\n",
    "        )\n",
    "        logger.info(f\"Accuracy:  {dev_acc_score}\")\n",
    "        logger.info(f\"AUC:  {dev_auc_score}\")\n",
    "        logger.info(f\"c@1:  {dev_c_at_1_score}\")\n",
    "        logger.info(f\"AUC x c@1:  {dev_auc_score * dev_c_at_1_score}\")\n",
    "        accs.append(dev_acc_score)\n",
    "        c_at_1s.append(dev_c_at_1_score)\n",
    "    return (accs, c_at_1s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/11/2023 05:05:56 [ruzicka:INFO] Fitting the provided score shifter on a 20.0% sample\n",
      "09/11/2023 05:05:57 [ruzicka:INFO] Fitting on 376 documents in instance mode...\n",
      "09/11/2023 05:05:57 [ruzicka:INFO] Running verifier on sub-sample\n",
      "09/11/2023 05:05:57 [ruzicka:INFO] Predicting on 188 documents\n",
      "09/11/2023 05:06:45 [ruzicka:INFO] Actually fitting...\n",
      "09/11/2023 05:06:50 [ruzicka:INFO] p1 for optimal combo: 0.59\n",
      "09/11/2023 05:06:50 [ruzicka:INFO] p2 for optimal combo: 0.794\n",
      "09/11/2023 05:06:50 [ruzicka:INFO] AUC for optimal combo: 0.9955862381167949\n",
      "09/11/2023 05:06:50 [ruzicka:INFO] c@1 for optimal combo: 0.9554096876414667\n",
      "09/11/2023 05:06:51 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:06:51 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] Accuracy:  0.8297872340425532\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] AUC:  0.9968311453146219\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] c@1:  0.9268899954730647\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] AUC x c@1:  0.9239528157680799\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:07:17 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:07:43 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:07:43 [ruzicka:INFO] Accuracy:  0.9148936170212766\n",
      "09/11/2023 05:07:43 [ruzicka:INFO] AUC:  0.9975101856043458\n",
      "09/11/2023 05:07:43 [ruzicka:INFO] c@1:  0.961973743775464\n",
      "09/11/2023 05:07:43 [ruzicka:INFO] AUC x c@1:  0.9595786076999704\n",
      "09/11/2023 05:07:44 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:07:44 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:08:10 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:08:10 [ruzicka:INFO] Accuracy:  0.851063829787234\n",
      "09/11/2023 05:08:10 [ruzicka:INFO] AUC:  0.9941149841557265\n",
      "09/11/2023 05:08:10 [ruzicka:INFO] c@1:  0.9208918062471706\n",
      "09/11/2023 05:08:10 [ruzicka:INFO] AUC x c@1:  0.9154723433765444\n",
      "09/11/2023 05:08:11 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:08:11 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] Accuracy:  0.9148936170212766\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] AUC:  0.9972838388411045\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] c@1:  0.9523540063377094\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] AUC x c@1:  0.9497672593761763\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:08:37 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:09:06 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:09:06 [ruzicka:INFO] Accuracy:  0.8829787234042553\n",
      "09/11/2023 05:09:06 [ruzicka:INFO] AUC:  0.9972838388411046\n",
      "09/11/2023 05:09:06 [ruzicka:INFO] c@1:  0.9393390674513353\n",
      "09/11/2023 05:09:06 [ruzicka:INFO] AUC x c@1:  0.936787671161291\n",
      "09/11/2023 05:09:07 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:09:07 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:09:34 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:09:34 [ruzicka:INFO] Accuracy:  0.8829787234042553\n",
      "09/11/2023 05:09:34 [ruzicka:INFO] AUC:  0.9970574920778632\n",
      "09/11/2023 05:09:34 [ruzicka:INFO] c@1:  0.965142598460842\n",
      "09/11/2023 05:09:34 [ruzicka:INFO] AUC x c@1:  0.9623026587188793\n",
      "09/11/2023 05:09:35 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:09:35 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:10:00 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:10:00 [ruzicka:INFO] Accuracy:  0.8404255319148937\n",
      "09/11/2023 05:10:00 [ruzicka:INFO] AUC:  0.9977365323675871\n",
      "09/11/2023 05:10:00 [ruzicka:INFO] c@1:  0.9298325033952014\n",
      "09/11/2023 05:10:00 [ruzicka:INFO] AUC x c@1:  0.9277278576202009\n",
      "09/11/2023 05:10:01 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:10:01 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:10:27 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:10:27 [ruzicka:INFO] Accuracy:  0.8936170212765957\n",
      "09/11/2023 05:10:27 [ruzicka:INFO] AUC:  0.9961521050248981\n",
      "09/11/2023 05:10:27 [ruzicka:INFO] c@1:  0.9581258488003621\n",
      "09/11/2023 05:10:27 [ruzicka:INFO] AUC x c@1:  0.954439081161248\n",
      "09/11/2023 05:10:28 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:10:28 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] Accuracy:  0.8723404255319149\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] AUC:  0.9934359438660028\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] c@1:  0.9533725667722952\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] AUC x c@1:  0.9471145757273888\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] Fitting on 423 documents in instance mode...\n",
      "09/11/2023 05:10:55 [ruzicka:INFO] Predicting on 94 documents\n",
      "09/11/2023 05:11:21 [ruzicka:INFO] Transforming 94 test scores...\n",
      "09/11/2023 05:11:21 [ruzicka:INFO] Accuracy:  0.8829787234042553\n",
      "09/11/2023 05:11:21 [ruzicka:INFO] AUC:  0.9956994114984156\n",
      "09/11/2023 05:11:21 [ruzicka:INFO] c@1:  0.9465821638750566\n",
      "09/11/2023 05:11:21 [ruzicka:INFO] AUC x c@1:  0.9425113035052906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=10, minmax=(0.8297872340425532, 0.9148936170212766), mean=0.876595744680851, variance=0.0008349680599567421, skewness=-0.23565052105781978, kurtosis=-0.9938307446654093)\n",
      "DescribeResult(nobs=10, minmax=(0.9208918062471706, 0.965142598460842), mean=0.9454504300588502, variance=0.00024022802128071785, skewness=-0.3218546731184984, kurtosis=-1.2880073646521866)\n"
     ]
    }
   ],
   "source": [
    "shifter = fit_shifter(\n",
    "    test_corpus.Chunk,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    vectorizer=vec_5grams,\n",
    "    verifier=verifier_nini,\n",
    "    shifter=ScoreShifter(min_spread=0.2),\n",
    ")\n",
    "aa, cc = benchmark_imposters(\n",
    "    test_corpus.Chunk, labels, sss, vec_5grams, verifier_nini, shifter\n",
    ")\n",
    "print(sp.stats.describe(aa))\n",
    "print(sp.stats.describe(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "09/11/2023 04:55:37 [ruzicka:INFO] Fitting the provided score shifter on a 20.0% sample\n",
      "09/11/2023 04:55:38 [ruzicka:INFO] Running verifier on sub-sample\n",
      "09/11/2023 04:55:38 [ruzicka:INFO] Training on 188 documents\n",
      "09/11/2023 04:56:27 [ruzicka:INFO] Actually fitting...\n",
      "09/11/2023 04:56:31 [ruzicka:INFO] p1 for optimal combo: 0.59\n",
      "09/11/2023 04:56:31 [ruzicka:INFO] p2 for optimal combo: 0.794\n",
      "09/11/2023 04:56:31 [ruzicka:INFO] AUC for optimal combo: 0.997906292440018\n",
      "09/11/2023 04:56:31 [ruzicka:INFO] c@1 for optimal combo: 0.9579560887279311\n"
     ]
    }
   ],
   "source": [
    "shifter = fit_shifter(\n",
    "    test_corpus.Chunk,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    vectorizer=vec_5grams,\n",
    "    verifier=verifier_nini,\n",
    "    shifter=ScoreShifter(min_spread=0.2),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngrams_std = make_pipeline(\n",
    "    TfidfVectorizer(\n",
    "        sublinear_tf=True,\n",
    "        use_idf=False,\n",
    "        norm=\"l2\",\n",
    "        analyzer=\"char\",\n",
    "        ngram_range=(2, 4),\n",
    "        max_features=5000,\n",
    "    ),\n",
    "    StandardScaler(with_mean=False),\n",
    "    FunctionTransformer(lambda x: x.todense(), accept_sparse=True),\n",
    "    Normalizer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "08/07/2023 03:50:40 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:50:44 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:50:47 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:50:51 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:50:54 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:50:57 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:50:59 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:51:02 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:51:04 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:51:07 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] Accuracy:  0.925531914893617\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] AUC:  0.9950203712086917\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] c@1:  0.925531914893617\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] AUC x c@1:  0.920923109522938\n",
      "08/07/2023 03:51:08 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:51:13 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:51:16 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:51:19 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:51:23 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:51:26 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:51:28 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:51:30 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:51:33 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:51:35 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] Accuracy:  0.9042553191489362\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] AUC:  0.9891353553644183\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] c@1:  0.9234947940244455\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] AUC x c@1:  0.9134613512645602\n",
      "08/07/2023 03:51:36 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:51:40 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:51:43 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:51:46 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:51:49 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:51:52 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:51:55 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:51:57 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:52:00 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:52:02 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] Accuracy:  0.9042553191489362\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] AUC:  0.9986419194205524\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] c@1:  0.9234947940244455\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] AUC x c@1:  0.9222406136794599\n",
      "08/07/2023 03:52:03 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:52:07 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:52:10 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:52:14 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:52:17 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:52:20 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:52:22 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:52:25 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:52:27 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:52:29 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] Accuracy:  0.925531914893617\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] AUC:  0.9959257582616569\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] c@1:  0.925531914893617\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] AUC x c@1:  0.9217610741357888\n",
      "08/07/2023 03:52:30 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:52:34 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:52:37 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:52:41 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:52:44 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:52:47 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:52:50 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:52:52 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:52:54 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:52:56 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] Accuracy:  0.9148936170212766\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] AUC:  0.9923042100497963\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] c@1:  0.9148936170212766\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] AUC x c@1:  0.9078527879178987\n",
      "08/07/2023 03:52:57 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:53:01 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:53:04 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:53:08 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:53:11 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:53:14 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:53:17 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:53:19 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:53:21 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:53:23 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] Accuracy:  0.925531914893617\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] AUC:  0.9945676776822092\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] c@1:  0.9353779990946128\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] AUC x c@1:  0.9302967243145607\n",
      "08/07/2023 03:53:24 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:53:28 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:53:31 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:53:34 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:53:38 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:53:41 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:53:44 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:53:46 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:53:48 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:53:50 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] Accuracy:  0.9148936170212766\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] AUC:  0.9923042100497963\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] c@1:  0.9246265278406519\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] AUC x c@1:  0.9175107963000041\n",
      "08/07/2023 03:53:51 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:53:55 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:53:58 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:54:02 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:54:05 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:54:08 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:54:11 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:54:13 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:54:15 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:54:17 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] Accuracy:  0.9361702127659575\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] AUC:  0.993662290629244\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] c@1:  0.9361702127659575\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] AUC x c@1:  0.9302370380358881\n",
      "08/07/2023 03:54:19 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:54:22 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:54:26 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:54:28 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:54:32 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:54:35 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:54:37 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:54:40 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:54:42 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:54:45 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] Accuracy:  0.8829787234042553\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] AUC:  0.9895880488909008\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] c@1:  0.9187415119963783\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] AUC x c@1:  0.9091756202915722\n",
      "08/07/2023 03:54:46 [ruzicka:INFO] Training on 423 training documents\n",
      "08/07/2023 03:54:50 [ruzicka:INFO] # test documents processed: 10 out of 94\n",
      "08/07/2023 03:54:53 [ruzicka:INFO] # test documents processed: 20 out of 94\n",
      "08/07/2023 03:54:57 [ruzicka:INFO] # test documents processed: 30 out of 94\n",
      "08/07/2023 03:55:00 [ruzicka:INFO] # test documents processed: 40 out of 94\n",
      "08/07/2023 03:55:03 [ruzicka:INFO] # test documents processed: 50 out of 94\n",
      "08/07/2023 03:55:05 [ruzicka:INFO] # test documents processed: 60 out of 94\n",
      "08/07/2023 03:55:08 [ruzicka:INFO] # test documents processed: 70 out of 94\n",
      "08/07/2023 03:55:10 [ruzicka:INFO] # test documents processed: 80 out of 94\n",
      "08/07/2023 03:55:12 [ruzicka:INFO] # test documents processed: 90 out of 94\n",
      "08/07/2023 03:55:14 [ruzicka:INFO] Transforming 94 test scores...\n",
      "08/07/2023 03:55:14 [ruzicka:INFO] Accuracy:  0.9361702127659575\n",
      "08/07/2023 03:55:14 [ruzicka:INFO] AUC:  0.9945676776822092\n",
      "08/07/2023 03:55:14 [ruzicka:INFO] c@1:  0.946129470348574\n",
      "08/07/2023 03:55:14 [ruzicka:INFO] AUC x c@1:  0.9409897901112798\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DescribeResult(nobs=10, minmax=(0.8829787234042553, 0.9361702127659575), mean=0.9170212765957448, variance=0.0002716161158895425, skewness=-0.7257747386024538, kurtosis=-0.18724279835387359)\n",
      "DescribeResult(nobs=10, minmax=(0.9148936170212766, 0.946129470348574), mean=0.9273992756903574, variance=8.53233427440122e-05, skewness=0.7423540401258779, kurtosis=-0.22444426820789998)\n"
     ]
    }
   ],
   "source": [
    "aa, cc = benchmark_imposters(\n",
    "    test_corpus.Chunk, labels, sss, ngrams_std, verifier, shifter\n",
    ")\n",
    "print(sp.stats.describe(aa))\n",
    "print(sp.stats.describe(cc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_verifier = Order2Verifier(\n",
    "    metric=\"nini\", base=\"instance\", nb_bootstrap_iter=1000, rnd_prop=0.35\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_verifier.fit(vectorizer.fit_transform(test_corpus.Chunk), labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>Work</th>\n",
       "      <th>Poem</th>\n",
       "      <th>LEN</th>\n",
       "      <th>Chunk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Nux</td>\n",
       "      <td>Nux</td>\n",
       "      <td>182</td>\n",
       "      <td>nuks ego junkta wiae kum sim sine krimine wita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Medicamina</td>\n",
       "      <td>Medicamina</td>\n",
       "      <td>100</td>\n",
       "      <td>diskite kwae fakiem kommendet kura puellae\\net...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>280</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Consolatio</td>\n",
       "      <td>Consolatio 1</td>\n",
       "      <td>158</td>\n",
       "      <td>wisa diu feliks mater modo dikta neronum\\njam ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Consolatio</td>\n",
       "      <td>Consolatio 2</td>\n",
       "      <td>158</td>\n",
       "      <td>at_kwutinam drusi manus alte_ret altera fratri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Consolatio</td>\n",
       "      <td>Consolatio 3</td>\n",
       "      <td>158</td>\n",
       "      <td>kwo raperis laniata komas similiskwe furenti\\n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Ibis</td>\n",
       "      <td>Ibis 1</td>\n",
       "      <td>64</td>\n",
       "      <td>tempus ad hok lustris bis jam mihi kwinkwe per...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Ibis</td>\n",
       "      <td>Ibis 2</td>\n",
       "      <td>200</td>\n",
       "      <td>di maris et terrae kwi_kwis meliora tenetis\\ni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Ibis</td>\n",
       "      <td>Ibis 3</td>\n",
       "      <td>200</td>\n",
       "      <td>kwi_kwokulis karuit per kwos male widerat auru...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>ps-Ovid</td>\n",
       "      <td>Ibis</td>\n",
       "      <td>Ibis 4</td>\n",
       "      <td>178</td>\n",
       "      <td>aut te dewoweat kertis abdera diebus\\nsaksakwe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Author        Work          Poem  LEN  \\\n",
       "278  ps-Ovid         Nux           Nux  182   \n",
       "279  ps-Ovid  Medicamina    Medicamina  100   \n",
       "280  ps-Ovid  Consolatio  Consolatio 1  158   \n",
       "281  ps-Ovid  Consolatio  Consolatio 2  158   \n",
       "282  ps-Ovid  Consolatio  Consolatio 3  158   \n",
       "283  ps-Ovid        Ibis        Ibis 1   64   \n",
       "284  ps-Ovid        Ibis        Ibis 2  200   \n",
       "285  ps-Ovid        Ibis        Ibis 3  200   \n",
       "286  ps-Ovid        Ibis        Ibis 4  178   \n",
       "\n",
       "                                                 Chunk  \n",
       "278  nuks ego junkta wiae kum sim sine krimine wita...  \n",
       "279  diskite kwae fakiem kommendet kura puellae\\net...  \n",
       "280  wisa diu feliks mater modo dikta neronum\\njam ...  \n",
       "281  at_kwutinam drusi manus alte_ret altera fratri...  \n",
       "282  kwo raperis laniata komas similiskwe furenti\\n...  \n",
       "283  tempus ad hok lustris bis jam mihi kwinkwe per...  \n",
       "284  di maris et terrae kwi_kwis meliora tenetis\\ni...  \n",
       "285  kwi_kwokulis karuit per kwos male widerat auru...  \n",
       "286  aut te dewoweat kertis abdera diebus\\nsaksakwe...  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "problems = corpus[corpus.Author == \"ps-Ovid\"]\n",
    "problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.968197662791219,\n",
       " 0.716,\n",
       " 0.9999872841514559,\n",
       " 0.8919025715266478,\n",
       " 0.9554818142471244,\n",
       " 0.9809135113353149,\n",
       " 0.9364080414309806,\n",
       " 0.9427659657030285,\n",
       " 0.8919025715266492]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "shifter.transform(\n",
    "    real_verifier.predict_proba(\n",
    "        vectorizer.transform(problems.Chunk),\n",
    "        lenc.transform([\"Ovid\"] * len(problems)),\n",
    "        nb_imposters=30,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.97566667, 1.        , 0.992     , 0.9975    ,\n",
       "       0.9995    , 0.9995    , 0.99633333, 0.993     ])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "real_verifier.predict_proba(\n",
    "    vectorizer.transform(problems.Chunk),\n",
    "    lenc.transform([\"Ovid\"] * len(problems)),\n",
    "    nb_imposters=30,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Ovid', 'Tibullus', 'Propertius', 'Catullus', 'Vergil', 'Juvenal',\n",
       "       'Silius', 'Statius', 'Lucan', 'V.Flaccus', 'Lucretius', 'Horace'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_corpus.Author.unique()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "208657b13d9d01f546253097cf6f870938d682edd7d0d269d6436fd16db9d0e7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
